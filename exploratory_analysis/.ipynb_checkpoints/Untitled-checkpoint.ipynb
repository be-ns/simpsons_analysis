{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import GradientBoostingRegressor as g_br, RandomForestRegressor as r_fr, AdaBoostRegressor as a_br\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neighbors import KNeighborsRegressor as k_nn\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split as tts, cross_val_score as cvs, RandomizedSearchCV as r_search\n",
    "from scipy.stats import randint as sp_randint\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_episode_data(filename):\n",
    "    '''\n",
    "    INPUT: filename\n",
    "    OUTPUT: Pandas DataFrame containing scrubbed data\n",
    "    '''\n",
    "    df = pd.read_csv(filename, sep=',').sort_values(by='id')\n",
    "    # initial dataframe cleaning\n",
    "    # drop columns that provide nothing useful for quantitative analysis\n",
    "    # change views to views in millions and drop original column\n",
    "    df['views'] = df['us_viewers_in_millions']\n",
    "    df.drop('us_viewers_in_millions', axis=1, inplace=True)\n",
    "    # turn the title into a metric for length of episode title\n",
    "    df['title_len'] = df['title'].apply(lambda x: len(x))\n",
    "    # change air date to datetime\n",
    "    df['original_air_date'] = pd.to_datetime(df['original_air_date'])\n",
    "    # Election cycle years are all divisible by four, (e.g. 2016) so I'm adding this info to see if it gives any insight to IMDB ratings\n",
    "    df['election_year'] = df['original_air_date'].apply(lambda x: 1 if x.year % 4 == 0 else 0)\n",
    "    # fill with backfill, since episodes are sequential, resets any missing values to be the same as the prior episode\n",
    "    df.fillna(method = 'bfill', inplace=True)\n",
    "    # drop any unnecesary columns\n",
    "    df.drop(labels=['title', 'image_url','video_url','imdb_votes', 'production_code'], axis=1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_location_data(script_df):\n",
    "    '''\n",
    "    INPUT: Script DataFrame\n",
    "    OUTPUT: Pandas Series with count of locations per episode\n",
    "    '''\n",
    "    return script_df.groupby('episode_id')['location_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_clean_script_df(fname, df):\n",
    "    '''\n",
    "    INPUT: filename as fname and the original episode DataFrame from `clean_episode_data`\n",
    "    OUTPUT: DF with extracted script info, sorted by episode\n",
    "    '''\n",
    "    # import errors for inconsistent use of quotations removed by `error_bad_lines` call, need to have some help with this\n",
    "    script_df = pd.read_csv(fname, error_bad_lines = False)\n",
    "    # keep only the normalized lines so capitalization isn't a problem\n",
    "    script_df.drop(labels = ['spoken_words', 'raw_text'], axis=1, inplace=True)\n",
    "    # get totals for the number of episodes of lines in each episode\n",
    "    line_series = script_df.groupby('episode_id')['speaking_line'].count()\n",
    "    # merge into episode df\n",
    "    # df = df.merge(pd.DataFrame(line_series), how='left', left_on = 'id', right_index=True)\n",
    "    # get words spoken per episode\n",
    "    line_length_series = script_df.groupby('episode_id')['word_count'].mean()\n",
    "    monologues = script_df.groupby('episode_id')['word_count'].max()\n",
    "    # merge into episode df\n",
    "    df = df.merge(pd.DataFrame(line_length_series), how='left', left_on = 'id', right_index=True)\n",
    "    df = df.merge(pd.DataFrame(monologues), how='left', left_on = 'id', right_index=True)\n",
    "    # get number of lines spoken by major characters (AKA the Simpsons)\n",
    "    major_char_lines = script_df.where(script_df['raw_character_text'].str.contains('Simpson')).groupby('episode_id')['speaking_line'].count()\n",
    "    # get ratio of lines spoken by Simpsons vs all\n",
    "    major_char_lines = major_char_lines / line_series\n",
    "    # merge the pandas Dataframes\n",
    "    df = df.merge(pd.DataFrame(major_char_lines), how='left', left_on = 'id',  right_index=True)\n",
    "    # get the count of locations from each episode\n",
    "    loc_series = add_location_data(script_df)\n",
    "    df = df.merge(pd.DataFrame(loc_series), how='left', left_on = 'id',  right_index=True)\n",
    "    print(df.columns.tolist())\n",
    "    #rename columns to avoid confusion\n",
    "    df.columns = ['id', 'original_air_date', 'season', 'number_in_season', 'number_in_series', 'views', 'imdb_rating', 'title_len', 'election_year', 'line_lengths', 'max_line_length', 'major_char_lines', 'locations_in_ep']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _fill_nans(df):\n",
    "    df.imdb_rating.fillna(df.imdb_rating.mean(), inplace=True)\n",
    "    df.major_char_lines.fillna(df.major_char_lines.mean(),inplace=True)\n",
    "    df.max_line_length.fillna(df.max_line_length.mean(),inplace=True)\n",
    "    df.line_lengths.fillna(df.line_lengths.mean(),inplace=True)\n",
    "    df.locations_in_ep.fillna(df.locations_in_ep.mean(), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2787: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'original_air_date', 'season', 'number_in_season', 'number_in_series', 'views', 'imdb_rating', 'title_len', 'election_year', 'word_count_x', 'word_count_y', 'speaking_line', 'location_id']\n"
     ]
    }
   ],
   "source": [
    "# read in episode data to Pandas DataFrame\n",
    "e_filename = '../data/simpsons_episodes.csv'\n",
    "# read in raw episode data, return clean episode pandas dataframe\n",
    "# loc_filename = 'simpsons_locations.csv'\n",
    "episode_df = return_clean_script_df(\"../../simpsons_analysis/data/simpsons_script_lines.csv\", clean_episode_data(e_filename))\n",
    "df = _fill_nans(episode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'original_air_date',\n",
       " 'season',\n",
       " 'number_in_season',\n",
       " 'number_in_series',\n",
       " 'views',\n",
       " 'imdb_rating',\n",
       " 'title_len',\n",
       " 'election_year',\n",
       " 'line_lengths',\n",
       " 'max_line_length',\n",
       " 'major_char_lines',\n",
       " 'locations_in_ep']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(df.line_lengths, df.imdb_rating, alpha = .3, s=100, label='IMDB episode Rating', color = '#002193')\n",
    "# ax.plot([1, 2], [ab_test, stacked_test], label = 'test')\n",
    "# ax.set_xlim((0,600))\n",
    "ax.tick_params(labelsize=10)\n",
    "ax.set_title('Top Feature, Avg Line Length in Episode', size=20)\n",
    "ax.set_xlabel('Avg Line Length', size=15)\n",
    "# ax.set_xticks([1, 2], set('AdaBoost', 'Gradient Boost'), rotation=45)\n",
    "ax.set_ylabel('IMDB Rating', size = 15)\n",
    "plt.legend(prop={'size':14})\n",
    "plt.tight_layout()\n",
    "plt.savefig('../graphs/avg_line_len.png', dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(df.major_char_lines, df.imdb_rating, alpha = .3, s=100, label='IMDB episode Rating', color = '#002193')\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_title('2nd Feature - Ratio of Lines spoken by the Simpsons', size=20)\n",
    "ax.set_xlabel('Ratio of lines by Simpson Family', size=15)\n",
    "ax.set_ylabel('IMDB Rating', size = 15)\n",
    "plt.legend(prop={'size':14})\n",
    "plt.tight_layout()\n",
    "plt.savefig('../graphs/Simpsons_to_other.png', dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(df.max_line_length, df.imdb_rating, alpha = .3, s=100, label='IMDB episode Rating', color = '#002193')\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_title('3rd Feature - Longest Line in Episode', size=20)\n",
    "ax.set_xlabel('length of longet line', size=15)\n",
    "ax.set_ylabel('IMDB Rating', size = 15)\n",
    "plt.legend(prop={'size':14})\n",
    "plt.tight_layout()\n",
    "plt.savefig('../graphs/longest_line.png', dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
